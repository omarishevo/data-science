"""
Interactive Data Science Dashboard
A comprehensive Streamlit app for data analysis, visualization, and machine learning
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy import stats
import plotly.express as px
import plotly.graph_objects as go
from io import StringIO
import warnings

warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="Data Science Dashboard",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .stAlert {
        padding: 1rem;
        margin: 1rem 0;
    }
    h1 {
        color: #1f77b4;
        padding-bottom: 1rem;
    }
    h2 {
        color: #ff7f0e;
        padding-top: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

# Helper Functions
def load_sample_data(dataset_name):
    """Load sample datasets for demonstration"""
    if dataset_name == "Iris":
        from sklearn.datasets import load_iris
        data = load_iris()
        df = pd.DataFrame(data.data, columns=data.feature_names)
        df['target'] = data.target
        df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})
        return df
    
    elif dataset_name == "Wine Quality":
        from sklearn.datasets import load_wine
        data = load_wine()
        df = pd.DataFrame(data.data, columns=data.feature_names)
        df['target'] = data.target
        return df
    
    elif dataset_name == "Boston Housing":
        # Generate synthetic housing data
        np.random.seed(42)
        n_samples = 506
        df = pd.DataFrame({
            'CRIM': np.random.exponential(3.6, n_samples),
            'RM': np.random.normal(6.3, 0.7, n_samples),
            'AGE': np.random.uniform(0, 100, n_samples),
            'DIS': np.random.exponential(3.8, n_samples),
            'LSTAT': np.random.exponential(12.6, n_samples),
            'PRICE': np.random.normal(22.5, 9, n_samples)
        })
        return df
    
    elif dataset_name == "Sales Data":
        # Generate synthetic sales data
        np.random.seed(42)
        dates = pd.date_range('2023-01-01', periods=365, freq='D')
        df = pd.DataFrame({
            'Date': dates,
            'Sales': np.random.poisson(100, 365) + np.sin(np.arange(365) * 2 * np.pi / 365) * 20,
            'Marketing_Spend': np.random.uniform(500, 2000, 365),
            'Temperature': np.random.normal(20, 10, 365),
            'Region': np.random.choice(['North', 'South', 'East', 'West'], 365)
        })
        return df

def generate_statistical_summary(df):
    """Generate comprehensive statistical summary"""
    summary = {
        'Shape': df.shape,
        'Columns': df.columns.tolist(),
        'Data Types': df.dtypes.to_dict(),
        'Missing Values': df.isnull().sum().to_dict(),
        'Memory Usage': f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
    }
    return summary

# Main App
def main():
    st.title("üìä Interactive Data Science Dashboard")
    st.markdown("**Explore, Analyze, and Model Your Data**")
    
    # Sidebar
    st.sidebar.title("‚öôÔ∏è Configuration")
    
    # Data Source Selection
    st.sidebar.header("1Ô∏è‚É£ Data Source")
    data_source = st.sidebar.radio(
        "Choose data source:",
        ["Upload CSV", "Sample Datasets"]
    )
    
    df = None
    
    if data_source == "Upload CSV":
        uploaded_file = st.sidebar.file_uploader(
            "Upload your CSV file",
            type=['csv']
        )
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            st.sidebar.success(f"‚úÖ Loaded {df.shape[0]} rows, {df.shape[1]} columns")
    else:
        dataset_choice = st.sidebar.selectbox(
            "Select a sample dataset:",
            ["Iris", "Wine Quality", "Boston Housing", "Sales Data"]
        )
        df = load_sample_data(dataset_choice)
        st.sidebar.success(f"‚úÖ Loaded {dataset_choice} dataset")
    
    if df is not None:
        # Analysis Mode Selection
        st.sidebar.header("2Ô∏è‚É£ Analysis Mode")
        analysis_mode = st.sidebar.selectbox(
            "Choose analysis type:",
            [
                "üìã Data Overview",
                "üìà Exploratory Analysis",
                "üîç Statistical Analysis",
                "ü§ñ Machine Learning",
                "üìä Interactive Visualizations"
            ]
        )
        
        # Main Content Area
        if analysis_mode == "üìã Data Overview":
            show_data_overview(df)
        
        elif analysis_mode == "üìà Exploratory Analysis":
            show_exploratory_analysis(df)
        
        elif analysis_mode == "üîç Statistical Analysis":
            show_statistical_analysis(df)
        
        elif analysis_mode == "ü§ñ Machine Learning":
            show_machine_learning(df)
        
        elif analysis_mode == "üìä Interactive Visualizations":
            show_interactive_visualizations(df)
    
    else:
        st.info("üëà Please upload a CSV file or select a sample dataset from the sidebar to begin.")
        
        # Show welcome information
        st.markdown("---")
        st.header("Welcome to the Data Science Dashboard! üéâ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("üìä Features")
            st.markdown("""
            - Data profiling & overview
            - Statistical analysis
            - Interactive visualizations
            - Machine learning models
            - Export capabilities
            """)
        
        with col2:
            st.subheader("üîß Technologies")
            st.markdown("""
            - Pandas & NumPy
            - Matplotlib & Seaborn
            - Plotly (interactive)
            - Scikit-learn (ML)
            - SciPy (statistics)
            """)
        
        with col3:
            st.subheader("üöÄ Get Started")
            st.markdown("""
            1. Upload your CSV file
            2. Or select a sample dataset
            3. Choose an analysis mode
            4. Explore your data!
            """)

def show_data_overview(df):
    """Display comprehensive data overview"""
    st.header("üìã Data Overview")
    
    # Dataset info
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Rows", df.shape[0])
    with col2:
        st.metric("Columns", df.shape[1])
    with col3:
        st.metric("Numeric Columns", df.select_dtypes(include=[np.number]).shape[1])
    with col4:
        st.metric("Missing Values", df.isnull().sum().sum())
    
    # Data preview
    st.subheader("Data Preview")
    n_rows = st.slider("Number of rows to display:", 5, min(100, len(df)), 10)
    st.dataframe(df.head(n_rows), use_container_width=True)
    
    # Column information
    st.subheader("Column Information")
    col_info = pd.DataFrame({
        'Column': df.columns,
        'Type': df.dtypes.values,
        'Non-Null Count': df.count().values,
        'Null Count': df.isnull().sum().values,
        'Unique Values': [df[col].nunique() for col in df.columns]
    })
    st.dataframe(col_info, use_container_width=True)
    
    # Statistical summary
    st.subheader("Statistical Summary")
    st.dataframe(df.describe(), use_container_width=True)
    
    # Missing values heatmap
    if df.isnull().sum().sum() > 0:
        st.subheader("Missing Values Heatmap")
        fig, ax = plt.subplots(figsize=(12, 6))
        sns.heatmap(df.isnull(), cbar=True, cmap='viridis', ax=ax)
        plt.title("Missing Values Pattern")
        st.pyplot(fig)
        plt.close()

def show_exploratory_analysis(df):
    """Display exploratory data analysis"""
    st.header("üìà Exploratory Data Analysis")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) == 0:
        st.warning("No numeric columns found for analysis.")
        return
    
    # Distribution Analysis
    st.subheader("Distribution Analysis")
    col1, col2 = st.columns(2)
    
    with col1:
        selected_col = st.selectbox("Select column for distribution:", numeric_cols)
    
    with col2:
        plot_type = st.selectbox("Plot type:", ["Histogram", "Box Plot", "Violin Plot", "KDE"])
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    if plot_type == "Histogram":
        ax.hist(df[selected_col].dropna(), bins=30, edgecolor='black', alpha=0.7)
        ax.set_xlabel(selected_col)
        ax.set_ylabel("Frequency")
        ax.set_title(f"Distribution of {selected_col}")
    
    elif plot_type == "Box Plot":
        ax.boxplot(df[selected_col].dropna())
        ax.set_ylabel(selected_col)
        ax.set_title(f"Box Plot of {selected_col}")
    
    elif plot_type == "Violin Plot":
        parts = ax.violinplot([df[selected_col].dropna()], showmeans=True, showmedians=True)
        ax.set_ylabel(selected_col)
        ax.set_title(f"Violin Plot of {selected_col}")
    
    elif plot_type == "KDE":
        df[selected_col].dropna().plot(kind='kde', ax=ax)
        ax.set_xlabel(selected_col)
        ax.set_ylabel("Density")
        ax.set_title(f"KDE Plot of {selected_col}")
    
    st.pyplot(fig)
    plt.close()
    
    # Correlation Analysis
    if len(numeric_cols) > 1:
        st.subheader("Correlation Analysis")
        
        corr_matrix = df[numeric_cols].corr()
        
        fig, ax = plt.subplots(figsize=(12, 10))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, linewidths=1, ax=ax, fmt='.2f')
        plt.title("Correlation Heatmap")
        st.pyplot(fig)
        plt.close()
        
        # Top correlations
        st.subheader("Top Correlations")
        corr_pairs = corr_matrix.unstack()
        corr_pairs = corr_pairs[corr_pairs != 1.0]
        top_corr = corr_pairs.abs().sort_values(ascending=False).head(10)
        
        for (var1, var2), corr_val in top_corr.items():
            actual_corr = corr_matrix.loc[var1, var2]
            st.write(f"**{var1}** ‚Üî **{var2}**: {actual_corr:.3f}")
    
    # Scatter plot
    if len(numeric_cols) >= 2:
        st.subheader("Scatter Plot Analysis")
        
        col1, col2 = st.columns(2)
        with col1:
            x_col = st.selectbox("X-axis:", numeric_cols, index=0)
        with col2:
            y_col = st.selectbox("Y-axis:", numeric_cols, index=min(1, len(numeric_cols)-1))
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.scatter(df[x_col], df[y_col], alpha=0.6)
        ax.set_xlabel(x_col)
        ax.set_ylabel(y_col)
        ax.set_title(f"{y_col} vs {x_col}")
        
        # Add regression line
        z = np.polyfit(df[x_col].dropna(), df[y_col].dropna(), 1)
        p = np.poly1d(z)
        ax.plot(df[x_col], p(df[x_col]), "r--", alpha=0.8, label=f'y={z[0]:.2f}x+{z[1]:.2f}')
        ax.legend()
        
        st.pyplot(fig)
        plt.close()

def show_statistical_analysis(df):
    """Display statistical analysis"""
    st.header("üîç Statistical Analysis")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) == 0:
        st.warning("No numeric columns found for analysis.")
        return
    
    # Hypothesis Testing
    st.subheader("Hypothesis Testing")
    
    test_type = st.selectbox(
        "Select test type:",
        ["T-Test (One Sample)", "T-Test (Two Independent)", "Chi-Square Test", "ANOVA"]
    )
    
    if test_type == "T-Test (One Sample)":
        col = st.selectbox("Select column:", numeric_cols)
        pop_mean = st.number_input("Population mean:", value=float(df[col].mean()))
        
        if st.button("Run Test"):
            t_stat, p_value = stats.ttest_1samp(df[col].dropna(), pop_mean)
            
            st.write(f"**T-statistic:** {t_stat:.4f}")
            st.write(f"**P-value:** {p_value:.4f}")
            
            if p_value < 0.05:
                st.success("‚úÖ Reject null hypothesis (p < 0.05)")
            else:
                st.info("‚ùå Fail to reject null hypothesis (p >= 0.05)")
    
    elif test_type == "T-Test (Two Independent)" and len(numeric_cols) >= 2:
        col1, col2 = st.columns(2)
        with col1:
            group1 = st.selectbox("Group 1:", numeric_cols, index=0)
        with col2:
            group2 = st.selectbox("Group 2:", numeric_cols, index=1)
        
        if st.button("Run Test"):
            t_stat, p_value = stats.ttest_ind(df[group1].dropna(), df[group2].dropna())
            
            st.write(f"**T-statistic:** {t_stat:.4f}")
            st.write(f"**P-value:** {p_value:.4f}")
            
            if p_value < 0.05:
                st.success("‚úÖ Reject null hypothesis (p < 0.05)")
            else:
                st.info("‚ùå Fail to reject null hypothesis (p >= 0.05)")
    
    # Normality Test
    st.subheader("Normality Testing")
    norm_col = st.selectbox("Select column for normality test:", numeric_cols, key='norm')
    
    if st.button("Test Normality"):
        stat, p_value = stats.shapiro(df[norm_col].dropna().sample(min(5000, len(df[norm_col].dropna()))))
        
        st.write(f"**Shapiro-Wilk statistic:** {stat:.4f}")
        st.write(f"**P-value:** {p_value:.4f}")
        
        if p_value < 0.05:
            st.warning("‚ö†Ô∏è Data is NOT normally distributed (p < 0.05)")
        else:
            st.success("‚úÖ Data appears normally distributed (p >= 0.05)")
        
        # Q-Q Plot
        fig, ax = plt.subplots(figsize=(8, 6))
        stats.probplot(df[norm_col].dropna(), dist="norm", plot=ax)
        ax.set_title(f"Q-Q Plot for {norm_col}")
        st.pyplot(fig)
        plt.close()
    
    # Descriptive Statistics
    st.subheader("Detailed Descriptive Statistics")
    desc_col = st.selectbox("Select column:", numeric_cols, key='desc')
    
    data = df[desc_col].dropna()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Mean", f"{data.mean():.2f}")
        st.metric("Median", f"{data.median():.2f}")
        st.metric("Mode", f"{data.mode().iloc[0]:.2f}" if len(data.mode()) > 0 else "N/A")
    
    with col2:
        st.metric("Std Dev", f"{data.std():.2f}")
        st.metric("Variance", f"{data.var():.2f}")
        st.metric("Range", f"{data.max() - data.min():.2f}")
    
    with col3:
        st.metric("Skewness", f"{data.skew():.2f}")
        st.metric("Kurtosis", f"{data.kurtosis():.2f}")
        st.metric("IQR", f"{data.quantile(0.75) - data.quantile(0.25):.2f}")

def show_machine_learning(df):
    """Display machine learning models"""
    st.header("ü§ñ Machine Learning")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) < 2:
        st.warning("Need at least 2 numeric columns for machine learning.")
        return
    
    # Model Selection
    st.subheader("Model Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        model_type = st.selectbox(
            "Select model type:",
            ["Classification", "Regression"]
        )
    
    with col2:
        target_col = st.selectbox("Select target variable:", numeric_cols)
    
    feature_cols = st.multiselect(
        "Select features:",
        [col for col in numeric_cols if col != target_col],
        default=[col for col in numeric_cols if col != target_col][:min(5, len(numeric_cols)-1)]
    )
    
    if len(feature_cols) == 0:
        st.warning("Please select at least one feature.")
        return
    
    test_size = st.slider("Test set size:", 0.1, 0.5, 0.2, 0.05)
    
    if st.button("Train Model"):
        # Prepare data
        X = df[feature_cols].dropna()
        y = df.loc[X.index, target_col]
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        with st.spinner("Training model..."):
            if model_type == "Classification":
                # Train Random Forest Classifier
                model = RandomForestClassifier(n_estimators=100, random_state=42)
                model.fit(X_train_scaled, y_train)
                
                y_pred = model.predict(X_test_scaled)
                
                # Results
                st.subheader("Classification Results")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("Training Accuracy", f"{model.score(X_train_scaled, y_train):.3f}")
                    st.metric("Test Accuracy", f"{model.score(X_test_scaled, y_test):.3f}")
                
                # Confusion Matrix
                with col2:
                    cm = confusion_matrix(y_test, y_pred)
                    fig, ax = plt.subplots(figsize=(8, 6))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
                    ax.set_title("Confusion Matrix")
                    ax.set_ylabel("True Label")
                    ax.set_xlabel("Predicted Label")
                    st.pyplot(fig)
                    plt.close()
                
                # Classification Report
                st.text("Classification Report:")
                st.text(classification_report(y_test, y_pred))
            
            else:  # Regression
                # Train Random Forest Regressor
                model = RandomForestRegressor(n_estimators=100, random_state=42)
                model.fit(X_train_scaled, y_train)
                
                y_pred = model.predict(X_test_scaled)
                
                # Results
                st.subheader("Regression Results")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("R¬≤ Score", f"{r2_score(y_test, y_pred):.3f}")
                
                with col2:
                    st.metric("RMSE", f"{np.sqrt(mean_squared_error(y_test, y_pred)):.3f}")
                
                with col3:
                    st.metric("MAE", f"{np.abs(y_test - y_pred).mean():.3f}")
                
                # Prediction vs Actual
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.scatter(y_test, y_pred, alpha=0.6)
                ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
                ax.set_xlabel("Actual Values")
                ax.set_ylabel("Predicted Values")
                ax.set_title("Predicted vs Actual Values")
                st.pyplot(fig)
                plt.close()
                
                # Residual Plot
                residuals = y_test - y_pred
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.scatter(y_pred, residuals, alpha=0.6)
                ax.axhline(y=0, color='r', linestyle='--')
                ax.set_xlabel("Predicted Values")
                ax.set_ylabel("Residuals")
                ax.set_title("Residual Plot")
                st.pyplot(fig)
                plt.close()
            
            # Feature Importance
            st.subheader("Feature Importance")
            feature_importance = pd.DataFrame({
                'Feature': feature_cols,
                'Importance': model.feature_importances_
            }).sort_values('Importance', ascending=False)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.barh(feature_importance['Feature'], feature_importance['Importance'])
            ax.set_xlabel("Importance")
            ax.set_title("Feature Importance")
            st.pyplot(fig)
            plt.close()

def show_interactive_visualizations(df):
    """Display interactive Plotly visualizations"""
    st.header("üìä Interactive Visualizations")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) == 0:
        st.warning("No numeric columns found for visualization.")
        return
    
    # Visualization type
    viz_type = st.selectbox(
        "Select visualization type:",
        ["Scatter Plot", "Line Chart", "Bar Chart", "3D Scatter", "Box Plot", "Violin Plot"]
    )
    
    if viz_type == "Scatter Plot" and len(numeric_cols) >= 2:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            x_col = st.selectbox("X-axis:", numeric_cols, index=0)
        with col2:
            y_col = st.selectbox("Y-axis:", numeric_cols, index=1)
        with col3:
            color_col = st.selectbox("Color by:", [None] + df.columns.tolist())
        
        fig = px.scatter(df, x=x_col, y=y_col, color=color_col,
                        title=f"{y_col} vs {x_col}",
                        hover_data=df.columns)
        st.plotly_chart(fig, use_container_width=True)
    
    elif viz_type == "Line Chart":
        y_cols = st.multiselect("Select columns to plot:", numeric_cols, default=numeric_cols[:3])
        
        if len(y_cols) > 0:
            fig = go.Figure()
            for col in y_cols:
                fig.add_trace(go.Scatter(y=df[col], name=col, mode='lines'))
            
            fig.update_layout(title="Line Chart", xaxis_title="Index", yaxis_title="Value")
            st.plotly_chart(fig, use_container_width=True)
    
    elif viz_type == "Bar Chart":
        col = st.selectbox("Select column:", numeric_cols)
        
        fig = px.bar(df, y=col, title=f"Bar Chart of {col}")
        st.plotly_chart(fig, use_container_width=True)
    
    elif viz_type == "3D Scatter" and len(numeric_cols) >= 3:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            x_col = st.selectbox("X-axis:", numeric_cols, index=0, key='3d_x')
        with col2:
            y_col = st.selectbox("Y-axis:", numeric_cols, index=1, key='3d_y')
        with col3:
            z_col = st.selectbox("Z-axis:", numeric_cols, index=2, key='3d_z')
        
        color_col = st.selectbox("Color by:", [None] + df.columns.tolist(), key='3d_color')
        
        fig = px.scatter_3d(df, x=x_col, y=y_col, z=z_col, color=color_col,
                           title=f"3D Scatter Plot")
        st.plotly_chart(fig, use_container_width=True)
    
    elif viz_type == "Box Plot":
        cols = st.multiselect("Select columns:", numeric_cols, default=numeric_cols[:min(5, len(numeric_cols))])
        
        if len(cols) > 0:
            fig = go.Figure()
            for col in cols:
                fig.add_trace(go.Box(y=df[col], name=col))
            
            fig.update_layout(title="Box Plot Comparison")
            st.plotly_chart(fig, use_container_width=True)
    
    elif viz_type == "Violin Plot":
        cols = st.multiselect("Select columns:", numeric_cols, default=numeric_cols[:min(5, len(numeric_cols))], key='violin')
        
        if len(cols) > 0:
            fig = go.Figure()
            for col in cols:
                fig.add_trace(go.Violin(y=df[col], name=col, box_visible=True))
            
            fig.update_layout(title="Violin Plot Comparison")
            st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()
